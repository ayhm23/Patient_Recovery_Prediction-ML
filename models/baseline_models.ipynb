{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348d0de7",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-22T18:20:50.549187Z",
     "iopub.status.busy": "2025-10-22T18:20:50.548909Z",
     "iopub.status.idle": "2025-10-22T18:23:40.570362Z",
     "shell.execute_reply": "2025-10-22T18:23:40.569246Z"
    },
    "papermill": {
     "duration": 170.026507,
     "end_time": "2025-10-22T18:23:40.571584",
     "exception": false,
     "start_time": "2025-10-22T18:20:50.545077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "train shape: (8000, 7), test shape: (2000, 6)\n",
      "\n",
      "Columns: ['Id', 'Therapy Hours', 'Initial Health Score', 'Lifestyle Activities', 'Average Sleep Hours', 'Follow-Up Sessions', 'Recovery Index']\n",
      "\n",
      "Train head:\n",
      "     Id  Therapy Hours  Initial Health Score Lifestyle Activities  \\\n",
      "0  9255              5                    49                   No   \n",
      "1  1562              2                    48                  Yes   \n",
      "2  1671              2                    81                   No   \n",
      "3  6088              2                    46                   No   \n",
      "4  6670              8                    47                   No   \n",
      "\n",
      "   Average Sleep Hours  Follow-Up Sessions  Recovery Index  \n",
      "0                    7                   5              36  \n",
      "1                    7                   6              25  \n",
      "2                    7                   2              59  \n",
      "3                    6                   1              22  \n",
      "4                    9                   0              40  \n",
      "\n",
      "--- EDA Summary ---\n",
      "\n",
      "Target variable summary:\n",
      "count    8000.000000\n",
      "mean       55.311500\n",
      "std        19.202059\n",
      "min        10.000000\n",
      "25%        40.000000\n",
      "50%        55.000000\n",
      "75%        71.000000\n",
      "max       100.000000\n",
      "Name: Recovery Index, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in train:\n",
      "                      missing_count  missing_pct\n",
      "Id                                0          0.0\n",
      "Therapy Hours                     0          0.0\n",
      "Initial Health Score              0          0.0\n",
      "Lifestyle Activities              0          0.0\n",
      "Average Sleep Hours               0          0.0\n",
      "Follow-Up Sessions                0          0.0\n",
      "Recovery Index                    0          0.0\n",
      "\n",
      "Missing values in test:\n",
      "                      missing_count  missing_pct\n",
      "Id                                0          0.0\n",
      "Therapy Hours                     0          0.0\n",
      "Initial Health Score              0          0.0\n",
      "Lifestyle Activities              0          0.0\n",
      "Average Sleep Hours               0          0.0\n",
      "Follow-Up Sessions                0          0.0\n",
      "\n",
      "Numeric features correlation with target:\n",
      "Recovery Index          1.000000\n",
      "Initial Health Score    0.914718\n",
      "Therapy Hours           0.376255\n",
      "Average Sleep Hours     0.044435\n",
      "Follow-Up Sessions      0.043888\n",
      "Id                      0.008825\n",
      "Name: Recovery Index, dtype: float64\n",
      "\n",
      "Numeric summary:\n",
      "                       count         mean          std   min      25%     50%  \\\n",
      "Id                    8000.0  5012.506875  2887.649416   2.0  2512.75  5014.5   \n",
      "Therapy Hours         8000.0     4.983250     2.594862   1.0     3.00     5.0   \n",
      "Initial Health Score  8000.0    69.531000    17.343735  40.0    54.75    70.0   \n",
      "Average Sleep Hours   8000.0     6.541625     1.698493   4.0     5.00     7.0   \n",
      "Follow-Up Sessions    8000.0     4.616500     2.861241   0.0     2.00     5.0   \n",
      "\n",
      "                          75%      max  \n",
      "Id                    7505.25  10000.0  \n",
      "Therapy Hours            7.00      9.0  \n",
      "Initial Health Score    85.00     99.0  \n",
      "Average Sleep Hours      8.00      9.0  \n",
      "Follow-Up Sessions       7.00      9.0  \n",
      "\n",
      "Lifestyle Activities distribution:\n",
      "Lifestyle Activities\n",
      "No     4043\n",
      "Yes    3957\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Preprocessing and Feature Engineering ---\n",
      "Combined shape: (10000, 7)\n",
      "Columns after rename: ['id', 'therapy_hours', 'initial_health_score', 'lifestyle_activities', 'average_sleep_hours', 'follow-up_sessions', 'is_train']\n",
      "\n",
      "Engineered features sample:\n",
      "   therapy_x_initial  sleep_x_initial  therapy_per_followup  \\\n",
      "0                245              343              0.833333   \n",
      "1                 96              336              0.285714   \n",
      "2                162              567              0.666667   \n",
      "3                 92              276              1.000000   \n",
      "4                376              423              8.000000   \n",
      "\n",
      "   sleep_per_therapy  initial_health_bin  low_sleep_flag  \n",
      "0           1.397206                   0               0  \n",
      "1           3.482587                   0               0  \n",
      "2           3.482587                   2               0  \n",
      "3           2.985075                   0               0  \n",
      "4           1.123596                   0               0  \n",
      "\n",
      "--- Handling missing values ---\n",
      "                      missing_count  missing_pct\n",
      "id                                0          0.0\n",
      "therapy_hours                     0          0.0\n",
      "initial_health_score              0          0.0\n",
      "lifestyle_activities              0          0.0\n",
      "average_sleep_hours               0          0.0\n",
      "follow_up_sessions                0          0.0\n",
      "is_train                          0          0.0\n",
      "therapy_x_initial                 0          0.0\n",
      "sleep_x_initial                   0          0.0\n",
      "therapy_per_followup              0          0.0\n",
      "sleep_per_therapy                 0          0.0\n",
      "initial_health_bin                0          0.0\n",
      "low_sleep_flag                    0          0.0\n",
      "Numeric features count: 11\n",
      "Categorical features: []\n",
      "\n",
      "Fitting preprocessor to combined data (numerics + categoricals)...\n",
      "Number of transformed features: 11\n",
      "Processed X_train shape: (8000, 11)\n",
      "Processed X_test shape: (2000, 11)\n",
      "y shape: (8000,)\n",
      "\n",
      "--- Feature selection via Lasso (sparse model) ---\n",
      "Retaining 11 features out of 11\n",
      "\n",
      "--- Model training and hyperparameter tuning ---\n",
      "Tuning Ridge...\n",
      "Ridge best RMSE (cv): 2.095094422352873 params: {'alpha': 0.01}\n",
      "Tuning Lasso...\n",
      "Lasso best RMSE (cv): 2.095106258628596 params: {'alpha': 0.0001}\n",
      "Tuning ElasticNet...\n",
      "ElasticNet best RMSE (cv): 2.0964163732464067 params: {'alpha': 0.0005, 'l1_ratio': 0.9}\n",
      "Tuning Random Forest (RandomizedSearchCV)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest best RMSE (cv): 2.2045082713367723 params: {'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'auto', 'max_depth': 10}\n",
      "Tuning Gradient Boosting (RandomizedSearchCV)...\n",
      "GradientBoosting best RMSE (cv): 2.1427923283440506 params: {'n_estimators': 400, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': 3, 'learning_rate': 0.1}\n",
      "Tuning XGBoost (RandomizedSearchCV)...\n",
      "XGBoost best RMSE (cv): 2.139436694231006 params: {'subsample': 0.6, 'n_estimators': 400, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.6}\n",
      "\n",
      "--- CV results summary ---\n",
      "Ridge: RMSE=2.09509, params={'alpha': 0.01}\n",
      "Lasso: RMSE=2.09511, params={'alpha': 0.0001}\n",
      "ElasticNet: RMSE=2.09642, params={'alpha': 0.0005, 'l1_ratio': 0.9}\n",
      "RandomForest: RMSE=2.20451, params={'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'auto', 'max_depth': 10}\n",
      "GradientBoosting: RMSE=2.14279, params={'n_estimators': 400, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': 3, 'learning_rate': 0.1}\n",
      "XGBoost: RMSE=2.13944, params={'subsample': 0.6, 'n_estimators': 400, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.6}\n",
      "\n",
      "Best model by CV RMSE: Ridge\n",
      "\n",
      "Training best model on full training data...\n",
      "Training performance - RMSE: 2.0926, MAE: 1.6620, R2: 0.9881\n",
      "\n",
      "Generating predictions on test set...\n",
      "Saved submission to /kaggle/working/submission.csv\n",
      "Saved best model to /kaggle/working/best_model.joblib\n",
      "\n",
      "Feature importance (if supported by model):\n",
      "                 feature  coefficient   abs_coef\n",
      "1   initial_health_score    37.592843  37.592843\n",
      "0          therapy_hours    15.646773  15.646773\n",
      "6        sleep_x_initial    -6.171743   6.171743\n",
      "3    average_sleep_hours     5.185401   5.185401\n",
      "8      sleep_per_therapy     3.037302   3.037302\n",
      "5      therapy_x_initial    -1.799297   1.799297\n",
      "4     follow_up_sessions     0.828582   0.828582\n",
      "2   lifestyle_activities     0.607055   0.607055\n",
      "9     initial_health_bin    -0.212628   0.212628\n",
      "10        low_sleep_flag    -0.206677   0.206677\n",
      "7   therapy_per_followup    -0.126174   0.126174\n",
      "\n",
      "Pipeline complete.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "Patient Recovery Predictive Modeling Pipeline\n",
    "Initial Baseline Models \n",
    "\n",
    "This notebook serves as our initial baseline for the Patient Recovery Prediction challenge. It uses a set of basic11 engineered features to train and evaluate a range of standard regression models.\n",
    "\n",
    "The models evaluated in this pass include:\n",
    "\n",
    "Ridge\n",
    "\n",
    "Lasso\n",
    "\n",
    "ElasticNet\n",
    "\n",
    "RandomForestRegressor\n",
    "\n",
    "GradientBoostingRegressor\n",
    "\n",
    "XGBRegressor\n",
    "\n",
    "The goal is to establish a preliminary performance benchmark. Based on cross-validation, the Ridge regression model yielded the lowest Root Mean Squared Error (RMSE) in this initial comparison.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# --- Imports and settings -------------------------------------------------\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, RobustScaler, PowerTransformer, PolynomialFeatures\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "# from sklearn.externals import joblib if hasattr(__import__('sklearn'), 'externals') else None\n",
    "\n",
    "# Try import xgboost gracefully\n",
    "try:\n",
    "    from xgboost import XGBRegressor\n",
    "    XGBOOST_AVAILABLE = True\n",
    "except Exception:\n",
    "    XGBOOST_AVAILABLE = False\n",
    "\n",
    "\n",
    "\n",
    "INPUT_DIR = Path('/kaggle/input/Patient-Recovery-Prediction-Challenge')\n",
    "OUTPUT_DIR = Path('/kaggle/working/')\n",
    "\n",
    "TRAIN_PATH = INPUT_DIR / 'train.csv'\n",
    "TEST_PATH = INPUT_DIR / 'test.csv'\n",
    "SAMPLE_SUB_PATH = INPUT_DIR / 'sample_submission.csv'\n",
    "\n",
    "# Output files should be saved in the /kaggle/working/ directory\n",
    "OUTPUT_PRED = OUTPUT_DIR / 'submission.csv'\n",
    "BEST_MODEL_PATH = OUTPUT_DIR / 'best_model.joblib'\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "N_JOBS = -1\n",
    "\n",
    "# --- Utility functions ---------------------------------------------------\n",
    "\n",
    "def rmse_cv(model, X, y, cv=5):\n",
    "    \"\"\"Return RMSE (averaged) from cross_val_score (negative RMSE scoring).\"\"\"\n",
    "    scores = cross_val_score(model, X, y, scoring='neg_root_mean_squared_error', cv=cv, n_jobs=N_JOBS)\n",
    "    return -scores.mean()\n",
    "\n",
    "\n",
    "def describe_missing(df):\n",
    "    miss = df.isnull().sum()\n",
    "    miss_pct = (miss / len(df)) * 100\n",
    "    return pd.concat([miss, miss_pct], axis=1, keys=['missing_count', 'missing_pct']).sort_values('missing_count', ascending=False)\n",
    "\n",
    "# --- Load data -----------------------------------------------------------\n",
    "print('Loading data...')\n",
    "train = pd.read_csv(TRAIN_PATH)\n",
    "test = pd.read_csv(TEST_PATH)\n",
    "sample_sub = pd.read_csv(SAMPLE_SUB_PATH)\n",
    "\n",
    "print(f'train shape: {train.shape}, test shape: {test.shape}')\n",
    "print('\\nColumns:', train.columns.tolist())\n",
    "\n",
    "# Quick glance\n",
    "print('\\nTrain head:')\n",
    "print(train.head())\n",
    "\n",
    "# --- Basic EDA ----------------------------------------------------------\n",
    "print('\\n--- EDA Summary ---')\n",
    "print('\\nTarget variable summary:')\n",
    "print(train['Recovery Index'].describe())\n",
    "\n",
    "# Target distribution\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.hist(train['Recovery Index'], bins=30)\n",
    "    plt.title('Recovery Index distribution')\n",
    "    plt.xlabel('Recovery Index')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Missing values\n",
    "print('\\nMissing values in train:')\n",
    "print(describe_missing(train))\n",
    "print('\\nMissing values in test:')\n",
    "print(describe_missing(test))\n",
    "\n",
    "# Correlation with target for numeric features (train)\n",
    "numeric_cols = train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numeric_cols.remove('Recovery Index')\n",
    "print('\\nNumeric features correlation with target:')\n",
    "print(train[numeric_cols + ['Recovery Index']].corr()['Recovery Index'].sort_values(ascending=False))\n",
    "\n",
    "# Check distributions and basic stats\n",
    "print('\\nNumeric summary:')\n",
    "print(train[numeric_cols].describe().T)\n",
    "\n",
    "# Categorical value counts\n",
    "if 'Lifestyle Activities' in train.columns:\n",
    "    print('\\nLifestyle Activities distribution:')\n",
    "    print(train['Lifestyle Activities'].value_counts(dropna=False))\n",
    "\n",
    "# --- Preprocessing & Feature Engineering --------------------------------\n",
    "print('\\n--- Preprocessing and Feature Engineering ---')\n",
    "# We'll combine train and test to ensure consistent pre-processing\n",
    "train['is_train'] = 1\n",
    "test['is_train'] = 0\n",
    "\n",
    "# Keep target separately\n",
    "y = train['Recovery Index'].copy()\n",
    "train.drop(columns=['Recovery Index'], inplace=True)\n",
    "\n",
    "combined = pd.concat([train, test], axis=0, ignore_index=True)\n",
    "print('Combined shape:', combined.shape)\n",
    "\n",
    "# Standardize column names\n",
    "combined.columns = [c.strip().replace(' ', '_').lower() for c in combined.columns]\n",
    "\n",
    "# Re-inspect columns\n",
    "print('Columns after rename:', combined.columns.tolist())\n",
    "\n",
    "# Rename helpful variables\n",
    "# Expected columns (after rename): therapy_hours, initial_health_score, lifestyle_activities, average_sleep_hours, follow-up_sessions -> follow_up_sessions\n",
    "combined.rename(columns={'follow-up_sessions': 'follow_up_sessions'}, inplace=True)\n",
    "\n",
    "# Basic cleaning: map lifestyle activities to binary\n",
    "if 'lifestyle_activities' in combined.columns:\n",
    "    combined['lifestyle_activities'] = combined['lifestyle_activities'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Feature engineering: interaction terms and ratios\n",
    "combined['therapy_x_initial'] = combined['therapy_hours'] * combined['initial_health_score']\n",
    "combined['sleep_x_initial'] = combined['average_sleep_hours'] * combined['initial_health_score']\n",
    "combined['therapy_per_followup'] = combined['therapy_hours'] / (combined['follow_up_sessions'] + 1)\n",
    "combined['sleep_per_therapy'] = combined['average_sleep_hours'] / (combined['therapy_hours'] + 0.01)\n",
    "\n",
    "# Binning initial health score into categories\n",
    "combined['initial_health_bin'] = pd.qcut(combined['initial_health_score'].rank(method='first'), q=4, labels=False)  # 0-3 quartiles\n",
    "\n",
    "# Flag for low sleep\n",
    "combined['low_sleep_flag'] = (combined['average_sleep_hours'] < 6).astype(int)\n",
    "\n",
    "# Winsorize (clip) extreme outliers for continuity\n",
    "for col in ['therapy_hours', 'initial_health_score', 'average_sleep_hours', 'follow_up_sessions', 'therapy_x_initial']:\n",
    "    if col in combined.columns:\n",
    "        lower = combined[col].quantile(0.01)\n",
    "        upper = combined[col].quantile(0.99)\n",
    "        combined[col] = combined[col].clip(lower, upper)\n",
    "\n",
    "# Show engineered features distribution sample\n",
    "print('\\nEngineered features sample:')\n",
    "print(combined[['therapy_x_initial', 'sleep_x_initial', 'therapy_per_followup', 'sleep_per_therapy', 'initial_health_bin', 'low_sleep_flag']].head())\n",
    "\n",
    "# --- Handling missing values --------------------------------------------\n",
    "print('\\n--- Handling missing values ---')\n",
    "print(describe_missing(combined))\n",
    "\n",
    "# Decide column types\n",
    "num_features = combined.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_features = combined.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# Remove utility columns\n",
    "if 'is_train' in num_features:\n",
    "    num_features.remove('is_train')\n",
    "if 'id' in num_features:\n",
    "    num_features.remove('id')\n",
    "\n",
    "# Some engineered features are numeric and included; keep them\n",
    "print('Numeric features count:', len(num_features))\n",
    "print('Categorical features:', cat_features)\n",
    "\n",
    "# Fill missing strategy:\n",
    "# - Numeric: median\n",
    "# - Categorical: constant 'missing'\n",
    "\n",
    "numeric_imputer = SimpleImputer(strategy='median')\n",
    "categorical_imputer = SimpleImputer(strategy='constant', fill_value='missing')\n",
    "\n",
    "# Column transformer for preprocessing\n",
    "# For numeric features, apply imputation + power transformer + scaling\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', numeric_imputer),\n",
    "    ('power', PowerTransformer(method='yeo-johnson', standardize=False)),\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "# For categorical (if any), impute and one-hot\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', categorical_imputer),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, num_features),\n",
    "    ('cat', categorical_transformer, cat_features)\n",
    "], remainder='drop')\n",
    "\n",
    "# Prepare final train/test matrices\n",
    "combined_processed = combined.copy()\n",
    "\n",
    "# Preserve IDs\n",
    "if 'id' in combined_processed.columns:\n",
    "    ids = combined_processed['id']\n",
    "else:\n",
    "    ids = pd.Series(np.arange(len(combined_processed)), name='id')\n",
    "\n",
    "# Fit preprocessor only on combined to ensure no leakage (it does include test too)\n",
    "print('\\nFitting preprocessor to combined data (numerics + categoricals)...')\n",
    "preprocessor.fit(combined_processed.drop(columns=['is_train']))\n",
    "X_all = preprocessor.transform(combined_processed.drop(columns=['is_train']))\n",
    "\n",
    "# Get feature names after transformation for feature importance mapping\n",
    "def get_feature_names_from_column_transformer(column_transformer):\n",
    "    feature_names = []\n",
    "    for name, transformer, columns in column_transformer.transformers_:\n",
    "        if name == 'remainder':\n",
    "            continue\n",
    "        if hasattr(transformer, 'named_steps') and 'onehot' in transformer.named_steps:\n",
    "            # OneHotEncoder\n",
    "            ohe = transformer.named_steps['onehot']\n",
    "            cols = list(columns)\n",
    "            ohe_names = ohe.get_feature_names_out(cols)\n",
    "            feature_names.extend(list(ohe_names))\n",
    "        else:\n",
    "            cols = list(columns)\n",
    "            feature_names.extend(cols)\n",
    "    return feature_names\n",
    "\n",
    "try:\n",
    "    feature_names = get_feature_names_from_column_transformer(preprocessor)\n",
    "except Exception:\n",
    "    # Generic fallback to numeric + categorical names\n",
    "    feature_names = num_features + cat_features\n",
    "\n",
    "print('Number of transformed features:', len(feature_names))\n",
    "\n",
    "# Split back into train and test\n",
    "X_combined = pd.DataFrame(X_all.toarray() if hasattr(X_all, 'toarray') else X_all, columns=feature_names)\n",
    "X_combined['is_train'] = combined['is_train'].values\n",
    "\n",
    "X_train = X_combined[X_combined['is_train'] == 1].drop(columns=['is_train']).reset_index(drop=True)\n",
    "X_test = X_combined[X_combined['is_train'] == 0].drop(columns=['is_train']).reset_index(drop=True)\n",
    "\n",
    "# Ensure shapes match\n",
    "print('Processed X_train shape:', X_train.shape)\n",
    "print('Processed X_test shape:', X_test.shape)\n",
    "\n",
    "# Align y index\n",
    "y = y.reset_index(drop=True)\n",
    "print('y shape:', y.shape)\n",
    "\n",
    "# --- Feature selection (optional) --------------------------------------\n",
    "# Use a simple model-based selection (Lasso) to remove extremely unimportant features\n",
    "print('\\n--- Feature selection via Lasso (sparse model) ---')\n",
    "feat_selector = Lasso(alpha=0.001, random_state=RANDOM_STATE, max_iter=20000)\n",
    "try:\n",
    "    feat_selector.fit(X_train, y)\n",
    "    importances = np.abs(feat_selector.coef_)\n",
    "    keep_idx = np.where(importances > 1e-4)[0]\n",
    "    print(f'Retaining {len(keep_idx)} features out of {X_train.shape[1]}')\n",
    "    X_train_sel = X_train.iloc[:, keep_idx]\n",
    "    X_test_sel = X_test.iloc[:, keep_idx]\n",
    "    selected_feature_names = X_train_sel.columns.tolist()\n",
    "except Exception as e:\n",
    "    print('Feature selection failed, skipping. Error:', e)\n",
    "    X_train_sel = X_train\n",
    "    X_test_sel = X_test\n",
    "    selected_feature_names = X_train_sel.columns.tolist()\n",
    "\n",
    "# --- Model building and hyperparameter tuning ---------------------------\n",
    "print('\\n--- Model training and hyperparameter tuning ---')\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "results = {}\n",
    "\n",
    "# 1) Ridge\n",
    "ridge = Ridge(random_state=RANDOM_STATE)\n",
    "ridge_params = {'alpha': [0.01, 0.1, 1.0, 5.0, 10.0, 50.0]}\n",
    "ridge_grid = GridSearchCV(ridge, ridge_params, scoring='neg_root_mean_squared_error', cv=cv, n_jobs=N_JOBS)\n",
    "print('Tuning Ridge...')\n",
    "ridge_grid.fit(X_train_sel, y)\n",
    "results['Ridge'] = {'best_score': -ridge_grid.best_score_, 'best_params': ridge_grid.best_params_}\n",
    "print('Ridge best RMSE (cv):', -ridge_grid.best_score_, 'params:', ridge_grid.best_params_)\n",
    "\n",
    "# 2) Lasso\n",
    "lasso = Lasso(random_state=RANDOM_STATE, max_iter=20000)\n",
    "lasso_params = {'alpha': [0.0001, 0.001, 0.01, 0.1, 1.0]}\n",
    "lasso_grid = GridSearchCV(lasso, lasso_params, scoring='neg_root_mean_squared_error', cv=cv, n_jobs=N_JOBS)\n",
    "print('Tuning Lasso...')\n",
    "lasso_grid.fit(X_train_sel, y)\n",
    "results['Lasso'] = {'best_score': -lasso_grid.best_score_, 'best_params': lasso_grid.best_params_}\n",
    "print('Lasso best RMSE (cv):', -lasso_grid.best_score_, 'params:', lasso_grid.best_params_)\n",
    "\n",
    "# 3) ElasticNet\n",
    "elastic = ElasticNet(random_state=RANDOM_STATE, max_iter=20000)\n",
    "elastic_params = {'alpha': [0.0005, 0.001, 0.005, 0.01, 0.05, 0.1], 'l1_ratio': [0.2, 0.5, 0.7, 0.9]}\n",
    "elastic_grid = GridSearchCV(elastic, elastic_params, scoring='neg_root_mean_squared_error', cv=cv, n_jobs=N_JOBS)\n",
    "print('Tuning ElasticNet...')\n",
    "elastic_grid.fit(X_train_sel, y)\n",
    "results['ElasticNet'] = {'best_score': -elastic_grid.best_score_, 'best_params': elastic_grid.best_params_}\n",
    "print('ElasticNet best RMSE (cv):', -elastic_grid.best_score_, 'params:', elastic_grid.best_params_)\n",
    "\n",
    "# 4) Random Forest (RandomizedSearchCV)\n",
    "rf = RandomForestRegressor(random_state=RANDOM_STATE)\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 200, 400],\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 0.5]\n",
    "}\n",
    "print('Tuning Random Forest (RandomizedSearchCV)...')\n",
    "rf_search = RandomizedSearchCV(rf, rf_params, n_iter=25, scoring='neg_root_mean_squared_error', cv=cv, random_state=RANDOM_STATE, n_jobs=N_JOBS)\n",
    "rf_search.fit(X_train_sel, y)\n",
    "results['RandomForest'] = {'best_score': -rf_search.best_score_, 'best_params': rf_search.best_params_}\n",
    "print('RandomForest best RMSE (cv):', -rf_search.best_score_, 'params:', rf_search.best_params_)\n",
    "\n",
    "# 5) Gradient Boosting (sklearn)\n",
    "gb = GradientBoostingRegressor(random_state=RANDOM_STATE)\n",
    "gb_params = {\n",
    "    'n_estimators': [100, 200, 400],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 8],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "print('Tuning Gradient Boosting (RandomizedSearchCV)...')\n",
    "gb_search = RandomizedSearchCV(gb, gb_params, n_iter=20, scoring='neg_root_mean_squared_error', cv=cv, random_state=RANDOM_STATE, n_jobs=N_JOBS)\n",
    "gb_search.fit(X_train_sel, y)\n",
    "results['GradientBoosting'] = {'best_score': -gb_search.best_score_, 'best_params': gb_search.best_params_}\n",
    "print('GradientBoosting best RMSE (cv):', -gb_search.best_score_, 'params:', gb_search.best_params_)\n",
    "\n",
    "# 6) XGBoost (if available)\n",
    "if XGBOOST_AVAILABLE:\n",
    "    xgb = XGBRegressor(objective='reg:squarederror', random_state=RANDOM_STATE, n_jobs=1)\n",
    "    xgb_params = {\n",
    "        'n_estimators': [100, 200, 400],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'max_depth': [3, 5, 8],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "    }\n",
    "    print('Tuning XGBoost (RandomizedSearchCV)...')\n",
    "    xgb_search = RandomizedSearchCV(xgb, xgb_params, n_iter=30, scoring='neg_root_mean_squared_error', cv=cv, random_state=RANDOM_STATE, n_jobs=N_JOBS)\n",
    "    xgb_search.fit(X_train_sel, y)\n",
    "    results['XGBoost'] = {'best_score': -xgb_search.best_score_, 'best_params': xgb_search.best_params_}\n",
    "    print('XGBoost best RMSE (cv):', -xgb_search.best_score_, 'params:', xgb_search.best_params_)\n",
    "else:\n",
    "    print('XGBoost not available in this environment; skipping.')\n",
    "\n",
    "# --- Summary of results -------------------------------------------------\n",
    "print('\\n--- CV results summary ---')\n",
    "for model_name, res in results.items():\n",
    "    print(f\"{model_name}: RMSE={res['best_score']:.5f}, params={res['best_params']}\")\n",
    "\n",
    "# Select best model by lowest RMSE\n",
    "best_model_name = min(results.items(), key=lambda x: x[1]['best_score'])[0]\n",
    "print('\\nBest model by CV RMSE:', best_model_name)\n",
    "\n",
    "# Instantiate best model with best params\n",
    "if best_model_name == 'Ridge':\n",
    "    best_model = Ridge(**results['Ridge']['best_params'], random_state=RANDOM_STATE)\n",
    "elif best_model_name == 'Lasso':\n",
    "    best_model = Lasso(**results['Lasso']['best_params'], random_state=RANDOM_STATE, max_iter=20000)\n",
    "elif best_model_name == 'ElasticNet':\n",
    "    best_model = ElasticNet(**results['ElasticNet']['best_params'], random_state=RANDOM_STATE, max_iter=20000)\n",
    "elif best_model_name == 'RandomForest':\n",
    "    best_model = RandomForestRegressor(**results['RandomForest']['best_params'], random_state=RANDOM_STATE)\n",
    "elif best_model_name == 'GradientBoosting':\n",
    "    best_model = GradientBoostingRegressor(**results['GradientBoosting']['best_params'], random_state=RANDOM_STATE)\n",
    "elif best_model_name == 'XGBoost' and XGBOOST_AVAILABLE:\n",
    "    best_model = XGBRegressor(**results['XGBoost']['best_params'], objective='reg:squarederror', random_state=RANDOM_STATE, n_jobs=1)\n",
    "else:\n",
    "    raise ValueError('Unexpected best model selection')\n",
    "\n",
    "# Train best model on entire training set\n",
    "print('\\nTraining best model on full training data...')\n",
    "best_model.fit(X_train_sel, y)\n",
    "\n",
    "# Evaluate on training with cross-validated metrics\n",
    "train_pred = best_model.predict(X_train_sel)\n",
    "train_rmse = mean_squared_error(y, train_pred, squared=False)\n",
    "train_mae = mean_absolute_error(y, train_pred)\n",
    "train_r2 = r2_score(y, train_pred)\n",
    "print(f'Training performance - RMSE: {train_rmse:.4f}, MAE: {train_mae:.4f}, R2: {train_r2:.4f}')\n",
    "\n",
    "# Predict on test\n",
    "print('\\nGenerating predictions on test set...')\n",
    "preds_test = best_model.predict(X_test_sel)\n",
    "\n",
    "# If necessary, round or clip predictions to match target constraints (10 to 100, rounded to nearest integer)\n",
    "preds_test = np.rint(np.clip(preds_test, 10, 100)).astype(int)\n",
    "\n",
    "# Create submission\n",
    "if 'id' in combined.columns:\n",
    "    test_ids = combined[combined['is_train'] == 0]['id'].values\n",
    "else:\n",
    "    test_ids = np.arange(len(preds_test))\n",
    "\n",
    "submission = pd.DataFrame({'id': test_ids, 'Recovery Index': preds_test})\n",
    "submission.to_csv(OUTPUT_PRED, index=False)\n",
    "print('Saved submission to', OUTPUT_PRED)\n",
    "\n",
    "# Save the best model\n",
    "try:\n",
    "    import joblib\n",
    "    joblib.dump(best_model, BEST_MODEL_PATH)\n",
    "    print('Saved best model to', BEST_MODEL_PATH)\n",
    "except Exception as e:\n",
    "    print('Could not save model using joblib. Error:', e)\n",
    "\n",
    "# Feature importance (if available)\n",
    "print('\\nFeature importance (if supported by model):')\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    importances = best_model.feature_importances_\n",
    "    imp_df = pd.DataFrame({'feature': selected_feature_names, 'importance': importances})\n",
    "    imp_df = imp_df.sort_values('importance', ascending=False).head(40)\n",
    "    print(imp_df)\n",
    "elif hasattr(best_model, 'coef_'):\n",
    "    coefs = best_model.coef_\n",
    "    imp_df = pd.DataFrame({'feature': selected_feature_names, 'coefficient': coefs})\n",
    "    imp_df['abs_coef'] = imp_df['coefficient'].abs()\n",
    "    imp_df = imp_df.sort_values('abs_coef', ascending=False).head(40)\n",
    "    print(imp_df)\n",
    "else:\n",
    "    print('Model does not expose importances/coefs.')\n",
    "\n",
    "print('\\nPipeline complete.')\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 13903632,
     "sourceId": 116123,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 176.881233,
   "end_time": "2025-10-22T18:23:43.193998",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-22T18:20:46.312765",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
